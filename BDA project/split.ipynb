{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created chunks\\chunk_1.csv with 138700 rows.\n",
      "Created chunks\\chunk_2.csv with 138700 rows.\n",
      "Created chunks\\chunk_3.csv with 138700 rows.\n",
      "Created chunks\\chunk_4.csv with 138700 rows.\n",
      "Created chunks\\chunk_5.csv with 138700 rows.\n",
      "Created chunks\\chunk_6.csv with 138700 rows.\n",
      "Created chunks\\chunk_7.csv with 138700 rows.\n",
      "Created chunks\\chunk_8.csv with 138700 rows.\n",
      "Created chunks\\chunk_9.csv with 138700 rows.\n",
      "Created chunks\\chunk_10.csv with 138700 rows.\n",
      "Created chunks\\chunk_11.csv with 138700 rows.\n",
      "Created chunks\\chunk_12.csv with 138700 rows.\n",
      "Created chunks\\chunk_13.csv with 138700 rows.\n",
      "Created chunks\\chunk_14.csv with 138700 rows.\n",
      "Created chunks\\chunk_15.csv with 138700 rows.\n",
      "Created chunks\\chunk_16.csv with 138700 rows.\n",
      "Created chunks\\chunk_17.csv with 138700 rows.\n",
      "Created chunks\\chunk_18.csv with 138700 rows.\n",
      "Created chunks\\chunk_19.csv with 138700 rows.\n",
      "Created chunks\\chunk_20.csv with 138700 rows.\n",
      "Created chunks\\chunk_21.csv with 138700 rows.\n",
      "Created chunks\\chunk_22.csv with 138700 rows.\n",
      "Created chunks\\chunk_23.csv with 138700 rows.\n",
      "Created chunks\\chunk_24.csv with 138700 rows.\n",
      "Created chunks\\chunk_25.csv with 138700 rows.\n",
      "Created chunks\\chunk_26.csv with 42933 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_csv(file_path, output_dir, max_file_size=25*1024*1024):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read the input CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate the number of rows per chunk to ensure each file is less than max_file_size\n",
    "    avg_row_size = df.memory_usage(index=True, deep=True).sum() / len(df)\n",
    "    rows_per_chunk = int(max_file_size / avg_row_size)\n",
    "    \n",
    "    # Split the DataFrame into chunks\n",
    "    num_chunks = (len(df) // rows_per_chunk) + 1\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_row = i * rows_per_chunk\n",
    "        end_row = min((i + 1) * rows_per_chunk, len(df))\n",
    "        \n",
    "        # Extract the chunk\n",
    "        chunk = df.iloc[start_row:end_row]\n",
    "        \n",
    "        # Define the output file name\n",
    "        output_file = os.path.join(output_dir, f\"chunk_{i+1}.csv\")\n",
    "        \n",
    "        # Save the chunk to a CSV file\n",
    "        chunk.to_csv(output_file, index=False)\n",
    "        print(f\"Created {output_file} with {len(chunk)} rows.\")\n",
    "\n",
    "# Usage\n",
    "input_file_path = 'daily_dataset.csv'\n",
    "output_directory = 'chunks'\n",
    "\n",
    "split_csv(input_file_path, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
